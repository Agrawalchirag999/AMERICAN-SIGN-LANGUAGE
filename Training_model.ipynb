{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.layers import Bidirectional\n",
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Activation,Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.679288</td>\n",
       "      <td>0.210996</td>\n",
       "      <td>0.613102</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574705</td>\n",
       "      <td>0.358198</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.360233</td>\n",
       "      <td>0.452296</td>\n",
       "      <td>0.350743</td>\n",
       "      <td>0.506043</td>\n",
       "      <td>0.339431</td>\n",
       "      <td>0.557486</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.635995</td>\n",
       "      <td>0.111589</td>\n",
       "      <td>0.496627</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.372887</td>\n",
       "      <td>0.124706</td>\n",
       "      <td>0.266505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.450521</td>\n",
       "      <td>0.479627</td>\n",
       "      <td>0.401771</td>\n",
       "      <td>0.453182</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.534598</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.602132</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272220</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.491623</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.370796</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.266032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641275</td>\n",
       "      <td>0.449075</td>\n",
       "      <td>0.491492</td>\n",
       "      <td>0.394166</td>\n",
       "      <td>0.473755</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.558699</td>\n",
       "      <td>0.346559</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77994</th>\n",
       "      <td>0.526264</td>\n",
       "      <td>0.677356</td>\n",
       "      <td>0.405371</td>\n",
       "      <td>0.684395</td>\n",
       "      <td>0.335519</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523216</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.434744</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.400675</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>0.488662</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.529258</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77995</th>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.684394</td>\n",
       "      <td>0.401440</td>\n",
       "      <td>0.688333</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.594382</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>0.458701</td>\n",
       "      <td>0.442549</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521610</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.525869</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.524858</td>\n",
       "      <td>0.478981</td>\n",
       "      <td>0.509965</td>\n",
       "      <td>0.520434</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77996</th>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.677694</td>\n",
       "      <td>0.397469</td>\n",
       "      <td>0.681666</td>\n",
       "      <td>0.327541</td>\n",
       "      <td>0.590112</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.455139</td>\n",
       "      <td>0.467794</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.435226</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.387353</td>\n",
       "      <td>0.518052</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.502548</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77997</th>\n",
       "      <td>0.532845</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.683759</td>\n",
       "      <td>0.322961</td>\n",
       "      <td>0.584981</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.448374</td>\n",
       "      <td>0.470393</td>\n",
       "      <td>0.373412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.511076</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.523066</td>\n",
       "      <td>0.379406</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.453426</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>0.487108</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77998</th>\n",
       "      <td>0.540281</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.413560</td>\n",
       "      <td>0.681854</td>\n",
       "      <td>0.333672</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>0.385783</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>0.457761</td>\n",
       "      <td>0.350155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.381493</td>\n",
       "      <td>0.530944</td>\n",
       "      <td>0.466449</td>\n",
       "      <td>0.521323</td>\n",
       "      <td>0.500644</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77999 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       0.1       0.2       0.3       0.4       0.5       0.6  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.299407  0.679288  0.210996  0.613102  0.150618  0.522777  0.127314   \n",
       "3      0.284236  0.729573  0.173007  0.635995  0.111589  0.496627  0.109330   \n",
       "4      0.272220  0.750940  0.151656  0.647857  0.090840  0.491623  0.096680   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77994  0.526264  0.677356  0.405371  0.684395  0.335519  0.593608  0.387241   \n",
       "77995  0.524471  0.684394  0.401440  0.688333  0.329967  0.594382  0.379672   \n",
       "77996  0.522581  0.677694  0.397469  0.681666  0.327541  0.590112  0.389733   \n",
       "77997  0.532845  0.682315  0.400254  0.683759  0.322961  0.584981  0.387589   \n",
       "77998  0.540281  0.675530  0.413560  0.681854  0.333672  0.586581  0.385783   \n",
       "\n",
       "            0.7       0.8       0.9  ...      0.33      0.34      0.35  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.438344  0.130090  0.381808  ...  0.574705  0.358198  0.506751   \n",
       "3      0.372887  0.124706  0.266505  ...  0.608846  0.450521  0.479627   \n",
       "4      0.370796  0.111904  0.266032  ...  0.641275  0.449075  0.491492   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77994  0.459165  0.450325  0.363955  ...  0.523216  0.504606  0.434744   \n",
       "77995  0.458701  0.442549  0.363953  ...  0.521610  0.506394  0.435055   \n",
       "77996  0.455139  0.467794  0.375672  ...  0.504175  0.501952  0.435226   \n",
       "77997  0.448374  0.470393  0.373412  ...  0.500650  0.511076  0.435591   \n",
       "77998  0.445418  0.457761  0.350155  ...  0.501399  0.510576  0.428731   \n",
       "\n",
       "           0.36      0.37      0.38      0.39      0.40      0.41  A  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  A  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  A  \n",
       "2      0.360233  0.452296  0.350743  0.506043  0.339431  0.557486  A  \n",
       "3      0.401771  0.453182  0.359019  0.534598  0.349776  0.602132  A  \n",
       "4      0.394166  0.473755  0.353244  0.558699  0.346559  0.625984  A  \n",
       "...         ...       ...       ...       ...       ...       ... ..  \n",
       "77994  0.525846  0.400675  0.525645  0.488662  0.509252  0.529258  Z  \n",
       "77995  0.525869  0.390700  0.524858  0.478981  0.509965  0.520434  Z  \n",
       "77996  0.517287  0.387353  0.518052  0.469302  0.505998  0.502548  Z  \n",
       "77997  0.523066  0.379406  0.523126  0.453426  0.514232  0.487108  Z  \n",
       "77998  0.529173  0.381493  0.530944  0.466449  0.521323  0.500644  Z  \n",
       "\n",
       "[77999 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\chira\\Downloads\\american.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']=df['A'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"A\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.679288</td>\n",
       "      <td>0.210996</td>\n",
       "      <td>0.613102</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295387</td>\n",
       "      <td>0.574705</td>\n",
       "      <td>0.358198</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.360233</td>\n",
       "      <td>0.452296</td>\n",
       "      <td>0.350743</td>\n",
       "      <td>0.506043</td>\n",
       "      <td>0.339431</td>\n",
       "      <td>0.557486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.635995</td>\n",
       "      <td>0.111589</td>\n",
       "      <td>0.496627</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.372887</td>\n",
       "      <td>0.124706</td>\n",
       "      <td>0.266505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285603</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.450521</td>\n",
       "      <td>0.479627</td>\n",
       "      <td>0.401771</td>\n",
       "      <td>0.453182</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.534598</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.602132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272220</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.491623</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.370796</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.266032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287473</td>\n",
       "      <td>0.641275</td>\n",
       "      <td>0.449075</td>\n",
       "      <td>0.491492</td>\n",
       "      <td>0.394166</td>\n",
       "      <td>0.473755</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.558699</td>\n",
       "      <td>0.346559</td>\n",
       "      <td>0.625984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77994</th>\n",
       "      <td>0.526264</td>\n",
       "      <td>0.677356</td>\n",
       "      <td>0.405371</td>\n",
       "      <td>0.684395</td>\n",
       "      <td>0.335519</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448133</td>\n",
       "      <td>0.523216</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.434744</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.400675</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>0.488662</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.529258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77995</th>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.684394</td>\n",
       "      <td>0.401440</td>\n",
       "      <td>0.688333</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.594382</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>0.458701</td>\n",
       "      <td>0.442549</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447349</td>\n",
       "      <td>0.521610</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.525869</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.524858</td>\n",
       "      <td>0.478981</td>\n",
       "      <td>0.509965</td>\n",
       "      <td>0.520434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77996</th>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.677694</td>\n",
       "      <td>0.397469</td>\n",
       "      <td>0.681666</td>\n",
       "      <td>0.327541</td>\n",
       "      <td>0.590112</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.455139</td>\n",
       "      <td>0.467794</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438479</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.435226</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.387353</td>\n",
       "      <td>0.518052</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.502548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77997</th>\n",
       "      <td>0.532845</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.683759</td>\n",
       "      <td>0.322961</td>\n",
       "      <td>0.584981</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.448374</td>\n",
       "      <td>0.470393</td>\n",
       "      <td>0.373412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444377</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.511076</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.523066</td>\n",
       "      <td>0.379406</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.453426</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>0.487108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77998</th>\n",
       "      <td>0.540281</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.413560</td>\n",
       "      <td>0.681854</td>\n",
       "      <td>0.333672</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>0.385783</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>0.457761</td>\n",
       "      <td>0.350155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453506</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.381493</td>\n",
       "      <td>0.530944</td>\n",
       "      <td>0.466449</td>\n",
       "      <td>0.521323</td>\n",
       "      <td>0.500644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77999 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       0.1       0.2       0.3       0.4       0.5       0.6  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.299407  0.679288  0.210996  0.613102  0.150618  0.522777  0.127314   \n",
       "3      0.284236  0.729573  0.173007  0.635995  0.111589  0.496627  0.109330   \n",
       "4      0.272220  0.750940  0.151656  0.647857  0.090840  0.491623  0.096680   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77994  0.526264  0.677356  0.405371  0.684395  0.335519  0.593608  0.387241   \n",
       "77995  0.524471  0.684394  0.401440  0.688333  0.329967  0.594382  0.379672   \n",
       "77996  0.522581  0.677694  0.397469  0.681666  0.327541  0.590112  0.389733   \n",
       "77997  0.532845  0.682315  0.400254  0.683759  0.322961  0.584981  0.387589   \n",
       "77998  0.540281  0.675530  0.413560  0.681854  0.333672  0.586581  0.385783   \n",
       "\n",
       "            0.7       0.8       0.9  ...      0.32      0.33      0.34  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.438344  0.130090  0.381808  ...  0.295387  0.574705  0.358198   \n",
       "3      0.372887  0.124706  0.266505  ...  0.285603  0.608846  0.450521   \n",
       "4      0.370796  0.111904  0.266032  ...  0.287473  0.641275  0.449075   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77994  0.459165  0.450325  0.363955  ...  0.448133  0.523216  0.504606   \n",
       "77995  0.458701  0.442549  0.363953  ...  0.447349  0.521610  0.506394   \n",
       "77996  0.455139  0.467794  0.375672  ...  0.438479  0.504175  0.501952   \n",
       "77997  0.448374  0.470393  0.373412  ...  0.444377  0.500650  0.511076   \n",
       "77998  0.445418  0.457761  0.350155  ...  0.453506  0.501399  0.510576   \n",
       "\n",
       "           0.35      0.36      0.37      0.38      0.39      0.40      0.41  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.506751  0.360233  0.452296  0.350743  0.506043  0.339431  0.557486  \n",
       "3      0.479627  0.401771  0.453182  0.359019  0.534598  0.349776  0.602132  \n",
       "4      0.491492  0.394166  0.473755  0.353244  0.558699  0.346559  0.625984  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "77994  0.434744  0.525846  0.400675  0.525645  0.488662  0.509252  0.529258  \n",
       "77995  0.435055  0.525869  0.390700  0.524858  0.478981  0.509965  0.520434  \n",
       "77996  0.435226  0.517287  0.387353  0.518052  0.469302  0.505998  0.502548  \n",
       "77997  0.435591  0.523066  0.379406  0.523126  0.453426  0.514232  0.487108  \n",
       "77998  0.428731  0.529173  0.381493  0.530944  0.466449  0.521323  0.500644  \n",
       "\n",
       "[77999 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATFRAME EXCLUDING LAST COLUMN\n",
    "X = df.iloc[:, :-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 25, 25, 25])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc=LabelEncoder()\n",
    "y = enc.fit_transform(df[['A']])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(1470, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(832, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(428, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(264, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(35, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.1269 - loss: 2.9680 - val_accuracy: 0.4217 - val_loss: 1.9128\n",
      "Epoch 2/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.3619 - loss: 2.0784 - val_accuracy: 0.4363 - val_loss: 1.8824\n",
      "Epoch 3/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.3965 - loss: 1.9764 - val_accuracy: 0.4688 - val_loss: 1.7710\n",
      "Epoch 4/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.4168 - loss: 1.9313 - val_accuracy: 0.4695 - val_loss: 1.7468\n",
      "Epoch 5/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.4273 - loss: 1.8925 - val_accuracy: 0.4939 - val_loss: 1.7258\n",
      "Epoch 6/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.4322 - loss: 1.8917 - val_accuracy: 0.4878 - val_loss: 1.7145\n",
      "Epoch 7/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.4459 - loss: 1.8568 - val_accuracy: 0.4800 - val_loss: 1.7167\n",
      "Epoch 8/100\n",
      "\u001b[1m1560/1560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.4466 - loss: 1.8514 - val_accuracy: 0.4751 - val_loss: 1.7260\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b7ed9c2ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7190051078796387, 0.48211538791656494]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Accuracy: 0.4821153846153846\n",
      "F1-score: 0.5741116750211898\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the validation set and compute performance metrics\n",
    "y_val_pred = model.predict(X_test)\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "acc = accuracy_score(y_test, y_val_pred_classes)\n",
    "f1 = f1_score(y_test, y_val_pred_classes, average='macro')\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
